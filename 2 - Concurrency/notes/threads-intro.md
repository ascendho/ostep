# threads-intro

## 核心结论
线程是进程内的**独立执行单元**，共享进程的地址空间（代码、堆、全局变量），但拥有独立的程序计数器（PC）、寄存器和栈。其核心价值是实现“并行加速”和“I/O与计算重叠”，但多线程访问共享数据时会因“无控制的调度”引发**竞态条件（Race Condition）**，需通过“原子操作”和“同步原语”保证临界区的互斥执行，才能获得确定结果——这也是操作系统课程重点学习该内容的核心原因（OS本身是首个并发程序，需保护内核共享数据）。

## 一、线程的本质与核心特性

### 1. 线程与进程的核心差异
| 特性                | 线程（Thread）                          | 进程（Process）                          |
|---------------------|-----------------------------------------|-----------------------------------------|
| 地址空间            | 共享所属进程的地址空间（代码、堆、全局变量） | 拥有独立的虚拟地址空间                  |
| 独立资源            | 独立PC、寄存器、栈（线程局部存储）        | 独立PCB、页表、文件描述符等            |
| 上下文切换          | 无需切换页表，开销低                    | 需切换页表，开销高                      |
| 数据共享            | 天然共享全局变量/堆，无需额外机制        | 需通过IPC（管道、共享内存）实现共享      |

### 2. 多线程的地址空间布局
- 单线程进程：地址空间仅有1个栈（通常从高地址向下增长），与堆（向上增长）之间有空闲区域；
- 多线程进程：每个线程有独立栈（分布在地址空间的空闲区域），共享代码段、堆和全局变量；
- 注意：多线程栈破坏了“栈-堆相向增长”的整洁布局，但因栈通常不大（递归场景除外），实际影响有限。

### 3. 线程的状态与上下文切换
- 线程状态：与进程一致（就绪、运行、阻塞），由OS调度器统一调度；
- 上下文切换：切换线程时，需保存当前线程的寄存器状态（到线程控制块TCB），恢复目标线程的寄存器状态，无需切换页表（地址空间不变），比进程切换快一个数量级。

## 二、使用线程的核心原因
### 1. 并行加速（Parallelism）
- 场景：CPU密集型任务（如大数组运算、数据处理）；
- 原理：多CPU/多核系统中，将任务拆分给多个线程，每个线程占用一个CPU核心，同时执行，缩短总耗时；
- 示例：两个线程分别计算数组的前半段和后半段，最终合并结果，比单线程快近一倍。

### 2. 避免I/O阻塞（Overlap I/O and Computation）
- 场景：I/O密集型任务（如网络通信、磁盘读写、页故障）；
- 原理：一个线程因I/O阻塞时（如等待磁盘响应），调度器可切换到其他就绪线程执行计算或发起新I/O，避免CPU空闲；
- 典型应用：Web服务器、数据库，通过多线程同时处理多个客户端请求，提升吞吐量。

### 3. 对比多进程的优势
- 数据共享更高效：线程天然共享进程地址空间，无需额外IPC机制，传递数据/状态的开销极低；
- 资源开销更低：线程创建、切换的开销远小于进程，支持更多并发单元。

## 三、线程创建与执行特性
### 1. 简单示例（Pthreads API）
```c
// 创建两个线程，分别打印"A"和"B"
#include <pthread.h>
void *mythread(void *arg) { printf("%s\n", (char *)arg); return NULL; }
int main() {
    pthread_t t1, t2;
    Pthread_create(&t1, NULL, mythread, "A"); // 创建线程t1
    Pthread_create(&t2, NULL, mythread, "B"); // 创建线程t2
    Pthread_join(t1, NULL); // 等待t1完成
    Pthread_join(t2, NULL); // 等待t2完成
    return 0;
}
```

### 2. 执行顺序的不确定性
- 线程创建后，执行顺序由OS调度器决定，与创建顺序无关；
- 可能的执行轨迹：
  1. 主线程→t1打印"A"→t2打印"B"→主线程结束；
  2. 主线程→创建t1后立即执行t1→创建t2后执行t2→主线程结束；
  3. 主线程→创建t1和t2→t2先执行打印"B"→t1再打印"A"→主线程结束；
- 核心：多线程执行的“交织顺序”不可预测，是后续竞态条件的根源。

## 四、核心问题：共享数据引发的竞态条件
### 1. 问题示例：共享计数器的异常
```c
static volatile int counter = 0; // 全局共享变量
void *mythread(void *arg) {
    for (int i = 0; i < 1e7; i++) {
        counter = counter + 1; // 共享数据更新
    }
    return NULL;
}
```
- 预期结果：两个线程各加1000万次，最终`counter=20000000`；
- 实际结果：每次运行结果不同（如19345221、19221041），均小于预期。

### 2. 问题根源：非原子的更新操作
`counter = counter + 1`在汇编层面被拆分为3条指令，并非“一步完成”：
1. `mov 0x8049a1c, %eax`：将内存中的`counter`值加载到寄存器`eax`；
2. `add $0x1, %eax`：寄存器值加1；
3. `mov %eax, 0x8049a1c`：将寄存器值写回内存。

- 关键风险：调度器可能在这3条指令之间触发中断（上下文切换），导致数据覆盖：
  1. 线程1加载`counter=50`到`eax`，加1后`eax=51`，此时被中断；
  2. 线程2加载`counter=50`到`eax`，加1后写回内存，`counter=51`；
  3. 线程1恢复执行，将`eax=51`写回内存，`counter`仍为51——两次更新仅生效一次。

### 3. 核心术语定义
- **临界区（Critical Section）**：访问共享资源（变量、数据结构）的代码段，需避免多线程并发执行；
- **竞态条件（Race Condition）**：多个线程并发进入临界区，导致执行结果依赖线程调度顺序（不确定）；
- **不确定性（Indeterminate）**：程序输出因线程交织顺序不同而变化，违背“计算机应产生确定结果”的直觉；
- **互斥（Mutual Exclusion）**：保证同一时间仅有一个线程进入临界区，是解决竞态条件的核心特性。

## 五、解决方案：原子性与同步原语
### 1. 核心需求：原子操作（Atomic Operation）
原子操作指“要么全执行，要么全不执行”的操作，不会被中断拆分——硬件需提供支持（如x86的`lock`前缀指令），例如：
- 理想原子指令：`memory-add 0x8049a1c, $0x1`（直接完成“加载-加1-写回”三步，不可中断）；
- 通用场景：无法为所有操作设计硬件原子指令（如B树更新），需基于硬件原子指令构建**同步原语**（如锁、信号量），将临界区包装为“原子块”。

### 2. 额外并发问题：线程间等待
除了临界区互斥，多线程还需解决“一个线程等待另一个线程完成某操作”的场景（如线程A等待线程B完成数据初始化后再执行），后续将通过“条件变量”实现该机制。

## 六、为什么操作系统课程要学线程与并发？
1. **OS本身是首个并发程序**：OS需同时处理多个进程的请求（如CPU调度、磁盘I/O、中断处理），内核中的共享数据（页表、进程列表、文件系统inode）均需通过同步保护，否则会出现数据错乱；
2. **应用开发的基础需求**：现代应用（服务器、数据库、GUI程序）均依赖多线程，OS需提供同步原语（锁、条件变量）支持应用开发；
3. **历史传承**：并发同步的核心技术（如互斥、原子操作）最初为解决OS自身的并发问题而发明，是OS设计的核心支柱之一。

## 七、作业方向（Simulation）
通过`x86.py`模拟器模拟线程交织与竞态条件，核心任务：
1. 单线程/多线程执行`loop.s`，观察寄存器值变化，验证线程独立性；
2. 运行`looping-race-nolock.s`，改变中断频率（`-i`）、线程数（`-t`）和随机种子（`-s`），观察竞态条件对共享变量结果的影响；
3. 定位临界区：分析中断在哪些指令区间触发会导致错误结果，明确临界区的精确范围；
4. 验证原子性：测试不同中断间隔对结果的影响，找出能保证“正确结果”的中断区间；
5. 分析`wait-for-me.s`的线程交互逻辑，理解线程等待的必要性与CPU利用率。
